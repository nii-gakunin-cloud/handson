{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "d03e89c2-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e8b0c-0b3d-11ec-a5ab-02420a01001e",
     "previous": null
    }
   },
   "source": [
    "# TensorFlow/MNISTによる手書き数字認識システムの構築\n",
    "\n",
    "---\n",
    "\n",
    "公開中の \"OpenHPC-v2\" テンプレートを使うと、クラウド上に GPU ノードクラスタを構築することができます。また、機械学習フレームワークである TensorFlow や Pytorch の環境もサポートしています。\n",
    "\n",
    "機械学習を使ったアプリケーション環境では、アプリケーションの実行環境では推論のみ行い、学習は別のシステムで行う場合が多くあります。これは、必要な計算能力やメモリ容量が「学習 >> 推論」であることや、秘密事項がある学習データをユーザーがアクセスする環境に置きたくないなどの理由によるものです。\n",
    "\n",
    "本ハンズオンでは、OpenHPC-v2 で構築した TensorFlow 環境を学習システムとした、手書き数字認識アプリケーション MNIST のアプリケーション実行環境を構築します。この学習環境の構築には時間を要するため、あらかじめ講師の学習環境で学習したニューラルネットのモデルと重みを使います。ハンズオンご参加の皆様には、このテンプレートでアプリ環境を構築していただきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "d03e8b0c-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e8c24-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e89c2-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "本テンプレートの流れ\n",
    "1. 構築環境情報の入力\n",
    "1. VCPの初期化\n",
    "1. CPUのみのVCノードの作成\n",
    "1. TensorFlow環境の構築\n",
    "1. MNISTによる手書き数字認識\n",
    "1. 環境の削除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "d03e8c24-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e8d0a-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e8b0c-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "## 構築環境情報の入力\n",
    "認識環境の構築情報を入力します。必要に応じ、下記の情報を修正してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "d03e8d0a-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e8de6-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e8c24-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# TensorFlow環境のユーザー名\n",
    "user = 'user00'\n",
    "\n",
    "###################################################\n",
    "### ハンズオンでは以下のパラメタを変更しないでください。###\n",
    "###################################################\n",
    "\n",
    "# unitgroup名\n",
    "ugroup_name = 'TfCpu'\n",
    "\n",
    "# プロバイダ\n",
    "vc_provider = 'aws'\n",
    "\n",
    "# フレーバー\n",
    "vcnode_flavor = 'small'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "d03e8de6-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e8ec2-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e8d0a-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "## VCP の初期化\n",
    "VCP を利用するために必要なアクセストークンを入力し、VCP SDK を初期化します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "d03e8ec2-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e8fb2-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e8de6-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### アクセストークンの入力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "d03e8fb2-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e9084-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e8ec2-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "vcc_access_token = getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "d03e9084-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e914c-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e8fb2-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### VCP の初期化\n",
    "VCP を初期化します。エラーになった場合、この章のセルを `unfreeze` してから、もう一度アクセストークンを入力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "d03e914c-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e9228-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e9084-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "from common import logsetting\n",
    "from vcpsdk.vcpsdk import VcpSDK\n",
    "\n",
    "# VCP SDKの初期化from vcpsdk.vcpsdk import VcpSDK\n",
    "vcp = VcpSDK(vcc_access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "lc_cell_meme": {
     "current": "d03e9228-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e9318-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e914c-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "## CPUのみのVCノードの作成\n",
    "クラウド上にCPUのみのインスタンスをVCノードとして作成します。\n",
    "* インスタンス：   \n",
    "* base コンテナ： ubuntu 16.04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03e9318-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e93ea-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e9228-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### VCノードのspecを指定する\n",
    "GPU環境で学習した重みを利用して、CPUのみで推論（本テンプレートの場合は手書き数字認識）するのに十分な性能・容量のノードspecを指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03e93ea-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e94c6-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e9318-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# UnitGroup の作成\n",
    "unit_group = vcp.create_ugroup(ugroup_name)\n",
    "\n",
    "# VCノード spec\n",
    "spec = vcp.get_spec(vc_provider, vcnode_flavor)\n",
    "\n",
    "# base コンテナ\n",
    "spec.image = \"vcp/base:1.6.2-ubuntu\"\n",
    "\n",
    "# ssh keyfiles\n",
    "import os\n",
    "ssh_public_key = os.path.expanduser('~/.ssh/id_rsa.pub')\n",
    "ssh_private_key = os.path.expanduser('~/.ssh/id_rsa')\n",
    "spec.set_ssh_pubkey(ssh_public_key)\n",
    "\n",
    "# ssh オプション\n",
    "ssh_opts = f\"-i {ssh_private_key} -l root\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03e94c6-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e95b6-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e93ea-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### Unitの作成とVCノードの起動\n",
    "Unitを作成します。Unitを作成すると同時に VCノード（ここでは Amazon EC2インスタンス）が起動します。処理が完了するまで1分半～2分程度かかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03e95b6-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e9692-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e94c6-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {},
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unitの作成（同時に VCノードが作成される）\n",
    "unit = unit_group.create_unit('tf-node', spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03e9692-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e9778-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e95b6-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### 疎通確認\n",
    "まず、sshのknown_hostsの設定を行います。その後、VCノードに対して`uname -a`を実行し、`ubuntu`が起動していることを確認します。`ubuntu`が起動していない場合は、`spec.image` に誤りがあります。本テンプレート下部にある「環境の削除」を実行、`spec.image`を修正、全てのセルを`unfreeze`してから、最初から再実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03e9778-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e984a-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e9692-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# unit_group.find_ip_addresses() は UnitGroup内の全VCノードのIPアドレスのリストを返します\n",
    "ip_address = unit_group.find_ip_addresses(node_state='RUNNING')[0] # 今は１つのVCノードのみ起動しているので [0] で最初の要素を取り出す\n",
    "print(ip_address)\n",
    "\n",
    "# ssh 設定\n",
    "!touch ~/.ssh/known_hosts\n",
    "!sleep 1\n",
    "!ssh-keygen -R {ip_address}    # ~/.ssh/known_hosts から古いホストキーを削除する\n",
    "!sleep 1\n",
    "!ssh-keyscan -H {ip_address} >> ~/.ssh/known_hosts    # ホストキーの登録\n",
    "\n",
    "# システムの確認\n",
    "!ssh {ssh_opts} {ip_address} uname -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "lc_cell_meme": {
     "current": "d03e984a-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e9930-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e9778-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "## TensorFlow環境の構築\n",
    "VCノード上に、TensorFlowのインストールページ(https://www.tensorflow.org/install) で紹介されているコンテナイメージを使用して環境を構築します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03e9930-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e99f8-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e984a-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### ユーザー登録\n",
    "作成した Unit に TensorFlow コンテナを実行するユーザーを登録します。便宜上このテンプレートでは、TensorFlow 環境のユーザーのsshの鍵として、この JupyterNotebook 環境の鍵を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03e99f8-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e9ade-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e9930-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {},
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ユーザー追加\n",
    "!ssh {ssh_opts} {ip_address} 'adduser --disabled-login --gecos \"\" {user}'\n",
    "!ssh {ssh_opts} {ip_address} usermod -aG 'docker' {user}\n",
    "\n",
    "# ssh 公開鍵設定\n",
    "!ssh {ssh_opts} {ip_address} mkdir -m 700 /home/{user}/.ssh\n",
    "!scp -i {ssh_private_key} {ssh_public_key} root@{ip_address}:/home/{user}/.ssh/authorized_keys\n",
    "!ssh {ssh_opts} {ip_address} chmod 600 /home/{user}/.ssh/authorized_keys\n",
    "!ssh {ssh_opts} {ip_address} chown -R {user}:{user} /home/{user}/.ssh/\n",
    "\n",
    "# ssh 疎通確認\n",
    "ssh_opts_user = f\"-i {ssh_private_key}\"\n",
    "target = f\"{user}@{ip_address}\"\n",
    "!ssh {ssh_opts_user} {target} id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03e9ade-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e9bb0-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e99f8-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### TensorFlow コンテナイメージの作成と実行\n",
    "ユーザーを追加した TensorFlow コンテナイメージを作成し実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03e9bb0-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e9caa-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e9ade-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# 最新のTensorFlowコンテナイメージのダウンロード\n",
    "docker_image = f'tensorflow/tensorflow:latest'\n",
    "!ssh {ssh_opts_user} {target} docker pull {docker_image}\n",
    "# !ssh {ssh_opts} {ip_address} docker info\n",
    "\n",
    "# ユーザーを追加したコンテナイメージの作成\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "!ssh {ssh_opts_user} {target} mkdir -p tensorflow-img\n",
    "out = !ssh {ssh_opts_user} {target} id -u\n",
    "uid = out[0]\n",
    "with TemporaryDirectory() as workdir:\n",
    "    dockerfile = Path(workdir) / 'Dockerfile'\n",
    "    with dockerfile.open(mode='w') as f:\n",
    "        f.write(f'''\n",
    "FROM {docker_image}\n",
    "\n",
    "ARG USER={user}\n",
    "RUN useradd -m ${{USER}} -u {uid}\n",
    "WORKDIR /home/${{USER}}\n",
    "USER {user}\n",
    "''')\n",
    "    !cat {dockerfile}\n",
    "    !scp {ssh_opts_user} {dockerfile} {target}:tensorflow-img\n",
    "\n",
    "!ssh {ssh_opts_user} {target} docker build -t tensorflow-{user} tensorflow-img\n",
    "\n",
    "# コンテナの実行\n",
    "!ssh {ssh_opts_user} {target} chmod 755 .\n",
    "!ssh {ssh_opts_user} {target} docker run -td -v /home/{user}:/home/{user} --rm --ipc=host --net=host --name tensorflow-{user} tensorflow-{user}\n",
    "!ssh {ssh_opts_user} {target} docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03e9caa-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e9d90-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e9bb0-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "以上で TensorFlow 環境の構築は完了です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "d03e9d90-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e9e76-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e9caa-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "## MNIST による手書き数字の認識\n",
    "機械学習アプリケーションとして、MNISTによる手書き数字認識を実行します。本章と次章を入れ替えれば、TensorFlowを使う別の機械学習アプリケーションの環境も構築できます。\n",
    "\n",
    "通常、データー入力と認識は同じシステムで実行することが多いですが、ハンズオン環境の都合上、手書き数字の入力はこの JupyterNotebook 環境で、認識(MNIST）は上で構築した TensorFlow 環境で実行します。入力データはファイルとして転送します。\n",
    "\n",
    "TensorFlow 環境での動作は、JupyterNotebook から事前に動作を定義したスクリプトを転送しておき、必要になった時点で JupyterNotebook から ssh で起動します。スクリプトは`402/scripts`に格納してあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "d03e9e76-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03e9f52-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e9d90-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### 実行環境の準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "d03e9f52-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03ea038-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e9e76-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "#### フリーハンド入力の準備\n",
    "フリーハンド入力機能の定義（プログラム）です。フリーハンド入力は、このJupyterNotebook上で実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "d03ea038-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03ea128-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03e9f52-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# フリーハンド入力環境定義\n",
    "drawpad = \"\"\"\n",
    "<canvas id=\"canvas\" height=\"280px\" width=\"280px\" style=\"border: 1px solid black;\"></canvas>\n",
    "<p>\n",
    "    <button id=\"clear\">Clear</button>\n",
    "    <button id=\"save\">Save</button>\n",
    "</p>\n",
    "<p id=\"mesg\"></p>\n",
    "\n",
    "<script type=\"text/javascript\">\n",
    "    // ====== variables ====== //\n",
    "    var kernel = IPython.notebook.kernel;\n",
    "    var btn_clear = document.getElementById(\"clear\");\n",
    "    var btn_save = document.getElementById(\"save\");\n",
    "    var canvas = document.getElementById(\"canvas\");\n",
    "    var context = canvas.getContext(\"2d\");\n",
    "\n",
    "    var isDrawing = false;\n",
    "    var x = 0;\n",
    "    var y = 0;\n",
    "\n",
    "    // ====== drawing ====== //\n",
    "    // cf. https://developer.mozilla.org/en-US/docs/Web/API/Element/mousemove_event#examples\n",
    "    canvas.addEventListener(\"mousedown\", function(e){\n",
    "        x = e.offsetX;\n",
    "        y = e.offsetY;\n",
    "        isDrawing = true;\n",
    "    });\n",
    "    \n",
    "    canvas.addEventListener(\"mousemove\", function(e){\n",
    "        if (isDrawing === true) {\n",
    "            drawLine(context, x, y, e.offsetX, e.offsetY);\n",
    "            x = e.offsetX;\n",
    "            y = e.offsetY;\n",
    "        }\n",
    "    });\n",
    "    \n",
    "    canvas.addEventListener(\"mouseup\", function(e){\n",
    "        if (isDrawing === true) {\n",
    "            drawLine(context, x, y, e.offsetX, e.offsetY);\n",
    "            x = 0;\n",
    "            y = 0;\n",
    "            isDrawing = false;\n",
    "        }\n",
    "    });\n",
    "    \n",
    "    canvas.addEventListener(\"mouseout\", function(){\n",
    "        x = 0;\n",
    "        y = 0;\n",
    "        isDrawing = false;\n",
    "    });\n",
    "\n",
    "    function drawLine(context, x1, y1, x2, y2) {\n",
    "        context.beginPath();\n",
    "        context.strokeStyle = 'black';\n",
    "        context.lineWidth = 14;\n",
    "        context.moveTo(x1, y1);\n",
    "        context.lineTo(x2, y2);\n",
    "        context.lineCap = \"round\";\n",
    "        context.stroke();\n",
    "    };\n",
    "\n",
    "\n",
    "    // ====== button ====== //\n",
    "    btn_clear.addEventListener(\"click\", function(){\n",
    "        context.clearRect(0, 0, canvas.width, canvas.height);\n",
    "        mesg.textContent = \"\";\n",
    "    });\n",
    "    \n",
    "    btn_save.addEventListener(\"click\", function(){\n",
    "        var img = 'base64_img';\n",
    "        kernel.execute(img + \" = '\" + canvas.toDataURL() + \"'\");\n",
    "        mesg.textContent = \"image saved\";\n",
    "    });\n",
    "   \n",
    "</script>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "d03ea128-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03ea20e-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03ea038-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "#### MNIST実行の準備\n",
    "クラウド上に構築した TensorFlow 環境で、MNIST による認識を実行するための準備です。JupyterNotebook から ssh で、TensorFlow 環境を操作します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "d03ea20e-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03ea308-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03ea128-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "MNIST による認識実行で必要なモジュールの TensorFlow 環境へのインストール、ファイル名とパスの設定、VCノード上の作業ディレクトリの作成、VCノード上の作業実行スクリプトのVCノードへの転送を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "d03ea308-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03ea3f8-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03ea20e-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# 必要なモジュールのインストール\n",
    "!ssh {ssh_opts_user} {target} docker exec -t -u {user} tensorflow-{user} pip install pillow\n",
    "!ssh {ssh_opts_user} {target} docker exec -t -u {user} tensorflow-{user} pip install matplotlib\n",
    "\n",
    "# ファイル名、パスの設定\n",
    "scripts = '402/scripts'         # VCノードで実行するスクリプトを格納しているディレクトリ（Jupyter上）\n",
    "model_dir  = '402/data'         # 学習済みモデル・重みファイルを格納しているディレクトリ（Jupyter上）\n",
    "model_file = 'saved_model.tgz'  # 学習済みモデル・重みファイル名（Jupyter、VCノード共通）\n",
    "work_dir = 'tensorflow'         # VCノード上の作業ディレクトリ名（VCノードのTensorFlowユーザホーム上）\n",
    "img_file = f'{model_dir}/base64_img.b64'  # フリーハンド入力した数字を格納するイメージファイル名（Jupyter上）\n",
    "\n",
    "# VCノード上の作業ディレクトリの作成\n",
    "!ssh {ssh_opts_user} {target} mkdir -p {work_dir}\n",
    "\n",
    "# VCノードで実行するスクリプトの転送\n",
    "!scp {ssh_opts_user} -qp {scripts}/*.py {target}:{work_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "d03ea3f8-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03ea4e8-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03ea308-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "#### MNISTのモデル・重みの準備\n",
    "GPUを持つ学習システムで学習したモデルと重みを、構築したTensorFlow環境にアップロードし展開します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "d03ea4e8-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03ea5c4-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03ea3f8-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# GPU環境で学習したモデルと重みのアップロードと展開\n",
    "!ssh {ssh_opts_user} {target} rm -rf {work_dir}/saved_model\n",
    "!scp {ssh_opts_user} -qp {model_dir}/{model_file} {target}:{work_dir}\n",
    "!ssh {ssh_opts_user} {target} '(cd {work_dir}; tar zxpf {model_file})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "d03ea5c4-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03ea68c-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03ea4e8-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# 実はTensorFlowのチュートリアル(初心者のための TensorFlow 2.0 入門)で紹介されているMNISTは、GPUを使わなく\n",
    "# ても1分以内で学習できます。後ほどコメントを外して試してみてください。\n",
    "# !ssh {ssh_opts_user} {target} docker exec -t -u {user} -w /home/{user}/{work_dir} tensorflow-{user} python3 download_mnist.py\n",
    "# !ssh {ssh_opts_user} {target} docker exec -t -u {user} -w /home/{user}/{work_dir} tensorflow-{user} python3 mnist_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "d03ea68c-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03ea75e-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03ea5c4-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### アプリケーションの実行： フリーハンド数字入力と認識\n",
    "数字（一桁の'0-9'）をフリーハンドで入力します。マウスをクリックしながら描画してください。描画が終わったら、`Save`ボタンをクリックし、２つ目のセルを実行してください。入力したイメージをVCノードのTensorFlow環境に転送し認識します。\n",
    "\n",
    "再実行：\n",
    "この入力環境は２つ目のセルを実行した後も機能しています。`Clear`で描画エリアをクリア後、再度入力し`Save`をクリックしてください。認識は２つ目のセルを`unfreeze`してから再実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "d03ea75e-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03ea830-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03ea68c-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# フリーハンド数字入力、base64形式イメージ化\n",
    "HTML(drawpad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "d03ea830-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03ea916-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03ea75e-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# イメージをファイルに保存\n",
    "with open(img_file, \"w\") as f1:\n",
    "    f1.write(base64_img)\n",
    "    \n",
    "# VCノードへ転送\n",
    "!scp {ssh_opts_user} -qp {img_file} {target}:{work_dir}\n",
    "\n",
    "# 確認のため MNIST の入力サイズ(28x28)に変換して、拡大表示\n",
    "img = Image.open(BytesIO(base64.b64decode(base64_img.split(\",\")[-1]))).resize((28,28))\n",
    "plt.imshow(np.asarray(img))\n",
    "plt.show()\n",
    "\n",
    "# MNIST による認識実行\n",
    "!ssh {ssh_opts_user} {target} docker exec -t -u {user} -w /home/{user}/{work_dir} tensorflow-{user} python3 mnist_predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "lc_cell_meme": {
     "current": "d03ea916-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03ea9e8-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03ea830-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "## 誤答が多い？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03ea9e8-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03eaac4-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03ea916-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "学習時のテストでは97%以上の精度が出ているのに、フリーハンド入力の認識では誤りが多いと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03eaac4-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03eab8c-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03ea9e8-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### 一般的な機械学習認識システムでの対応\n",
    "アプリ運用中に誤答が多くなると、誤答データ（イメージ）と正解ラベルを学習システムに戻して追加学習し、この重みで認識システムを更新します。\n",
    "\n",
    "学習システムはオンデマンドにあれば良いので、本サービスの様にオンデマンドに起動するシステムがあると便利です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03eab8c-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03eac54-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03eaac4-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### なぜ、誤答が多い？\n",
    "このテンプレートのMNISTのモデルは、TensorFlowホームページの「初心者のための TensorFlow 2.0 入門」を基にしています。モデルは、フラットな４層ニューラルネットです（{scripts}/mnist_train.py 参照）。\n",
    "\n",
    "一般に、フラットなモデルでは、学習データにない筆者の手書き文字を認識するのは難しいと考えられます。学習時のテストで97%以上の高い精度を示したのは、テストデータの中に学習データと同じ筆者のデータが含まれているためと思われます。\n",
    "\n",
    "学習データにない筆者の手書き認識文字では、畳み込みニューラルネットワーク（CNN）がよく使われます。フラットなネットワークとの違いは、\n",
    "\n",
    "* CNN: 畳み込み層はイメージまたは前層の出力の小領域の部分特徴を認識します。次の畳み込み層では前層の部分特徴の組み合わせをさらに部分特徴として認識します（結果として、前層より入力層の大きな部分を見ることになります）。これを積み重ねることにより、最終的に全体を認識します\n",
    "* フラット: 各層でイメージまたは前層の出力全体を認識します\n",
    "\n",
    "全体しか見ない構造では、変形や位置ずれで誤認識しやすくなります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03eac54-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03ead30-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03eab8c-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### どうする？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03ead30-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03eae0c-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03eac54-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# そこで、CNNで学習した重みも用意してあります。興味のある方は試してみてください。\n",
    "# モデル構成は、{scripts}/mnist_train_cnn.py を参照してください。\n",
    "\n",
    "# CNNで学習済みモデル・重みファイル名\n",
    "model_file = 'saved_model2.tgz'\n",
    "\n",
    "# GPU環境で学習したモデルと重みのダウンロードと展開\n",
    "!ssh {ssh_opts_user} {target} rm -rf {work_dir}/saved_model\n",
    "!scp {ssh_opts_user} -qp {model_dir}/{model_file} {target}:{work_dir}\n",
    "!ssh {ssh_opts_user} {target} '(cd {work_dir}; tar zxpf {model_file})'\n",
    "\n",
    "# あとはフリーハンド入力のセルに戻って試してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03eae0c-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03eaee8-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03ead30-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# 実は、CPUだけのVCノードでも学習可能です。8分程度必要です。興味があれば試してみてください。\n",
    "# !ssh {ssh_opts_user} {target} docker exec -t -u {user} -w /home/{user}/{work_dir} tensorflow-{user} python3 download_mnist.py\n",
    "# !ssh {ssh_opts_user} {target} docker exec -t -u {user} -w /home/{user}/{work_dir} tensorflow-{user} python3 mnist_train_cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03eaee8-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03eafba-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03eae0c-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### CNNを試した方へ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03eafba-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03eb08c-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03eaee8-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "source": [
    "CNNを使っても、あまり認識率が上がらないと思います。\n",
    "\n",
    "原因の一つとして、モデルの層が少ないことが考えられます。今回使用したCNNは４層です（CNNは最初の2層のみ）。ニューラルネットは層が多いほど複雑な動作ができます。例えば、AND や OR は中間層のない１層で学習できますが、XOR では少なくとも１つの中間層が必要です（２層モデル）。認識精度の高いニューラルネットでは１００層を超えます。\n",
    "\n",
    "このテンプレートではここまでとしますが、興味ある方は {scripts}/mnist_train_cnn.py を編集して試してみてください。（この環境では学習時間がかかり過ぎますが...）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "lc_cell_meme": {
     "current": "d03eb08c-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03eb15e-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03eafba-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "## 環境の削除\n",
    "TensorFlowコンテナを停止し、全てのリソースを削除します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03eb15e-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03eb24e-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03eb08c-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### TensorFlowコンテナの停止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03eb24e-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03eb30c-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03eb15e-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# TensorFlowコンテナの停止\n",
    "!ssh {ssh_opts_user} {target} docker stop tensorflow-{user}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03eb30c-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03eb3de-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03eb24e-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "### リソースの削除\n",
    "ここまで作成した全てのリソース（UnitGroup, Unit、VCノード）を削除します。この操作を行うことで AWS EC2インスタンスやAzure VMなどのクラウドに作成したリソースが削除されます。\n",
    "\n",
    "> 全てのリソースの削除には 4～5分程度かかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03eb3de-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03eb4c4-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03eb30c-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {},
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unit_group.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03eb4c4-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03eb58c-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03eb3de-0b3d-11ec-a5ab-02420a01001e"
    }
   },
   "source": [
    "削除後の状態の確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03eb58c-0b3d-11ec-a5ab-02420a01001e",
     "next": "d03eb654-0b3d-11ec-a5ab-02420a01001e",
     "previous": "d03eb4c4-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {},
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# UnitGroupの一覧を DataFrame で表示する\n",
    "vcp.df_ugroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lc_cell_meme": {
     "current": "d03eb654-0b3d-11ec-a5ab-02420a01001e",
     "next": null,
     "previous": "d03eb58c-0b3d-11ec-a5ab-02420a01001e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# UnitGroup強制削除\n",
    "# UnitGroup作成後、エラーが発生するなど強制的に削除する必要が生じた場合のみ、コメントを外して利用します。\n",
    "# ugroup = vcp.get_ugroup('TfCpu')\n",
    "# ugroup.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "826px",
    "left": "0px",
    "right": "1202px",
    "top": "111px",
    "width": "310px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
